.\" Copyright (C) 2022 Jens Axboe <axboe@kernel.dk>
.\"
.\" SPDX-License-Identifier: LGPL-2.0-or-later
.\"
.TH io_uring_prep_recv 3 "March 12, 2022" "liburing-2.2" "liburing Manual"
.SH NAME
io_uring_prep_recv \- prepare a recv request
.SH SYNOPSIS
.nf
.B #include <liburing.h>
.PP
.BI "void io_uring_prep_recv(struct io_uring_sqe *" sqe ","
.BI "                        int " sockfd ","
.BI "                        void *" buf ","
.BI "                        size_t " len ","
.BI "                        int " flags ");"
.PP
.BI "void io_uring_prep_recv_multishot(struct io_uring_sqe *" sqe ","
.BI "                                  int " sockfd ","
.BI "                                  void *" buf ","
.BI "                                  size_t " len ","
.BI "                                  int " flags ");"
.fi
.SH DESCRIPTION
.PP
The
.BR io_uring_prep_recv (3)
function prepares a recv request. The submission
queue entry
.I sqe
is setup to use the file descriptor
.I sockfd
to start receiving the data into the destination buffer
.I buf
of size
.I len
and with modifier flags
.IR flags .

This function prepares an async
.BR recv (2)
request. See that man page for details on the arguments specified to this
prep helper.

The multishot version allows the application to issue a single receive request,
which repeatedly posts a CQE when data is available. It requires length to
be 0, the
.B IOSQE_BUFFER_SELECT
flag to be set and no
.B MSG_WAITALL
flag to be set.
Therefore each CQE will take a buffer out of a provided buffer pool for receiving.
The application should check the flags of each CQE, regardless of its result.
If a posted CQE does not have the
.B IORING_CQE_F_MORE
flag set, then the multishot receive is done and the application must issue a
new request if it still wishes to receive data from the socket.
Multishot variants are available since kernel 6.0.


After calling this function, additional io_uring internal modifier flags
may be set in the SQE
.I ioprio
field. The following flags are supported:
.TP
.B IORING_RECVSEND_POLL_FIRST
If set, io_uring will assume the socket is currently empty and attempting to
receive data will be unsuccessful. For this case, io_uring will arm internal
poll and trigger a receive of the data when the socket has data to be read.
This initial receive attempt can be wasteful for the case where the socket
is expected to be empty, setting this flag will bypass the initial receive
attempt and go straight to arming poll. If poll does indicate that data is
ready to be received, the operation will proceed.

Can be used with the CQE
.B IORING_CQE_F_SOCK_NONEMPTY
flag, which io_uring will set on CQEs after a
.BR recv (2)
or
.BR recvmsg (2)
operation. If set, the socket still had data to be read after the operation
completed. Both these flags are available since 5.19.

.TP
.B IORING_RECVSEND_BUNDLE
If set and provided buffers are used with
.B IOSQE_BUFFER_SELECT ,
the receive operation will attempt to fill multiple buffers with rather than
just pick a single buffer to fill. To receive multiple buffers in a single
receive, the buffer group ID set in the SQE must be of the ring provided type.
If set, the CQE
.I res
field indicates the total number of bytes received, and the buffer ID returned
in the CQE
.I flags
field indicates the first buffer in the receive operation. The application must
process the indicated initial buffer ID and until all
.I res
bytes have been seen to know which is the last buffer in the receive operation.
The buffers consumed will be contiguous from the initial buffer, in the order
in which they appear in the buffer ring. The CQE struct does not contain
the position of the buffer in the buffer ring, therefore in order to identify
buffers contained by the bundle, it is advised to maintain the cached head
index per buffer ring. This uint16_t index represents the position of the next
buffer to be consumed within the ring. Upon completion of a receive operation,
the cached head index should be incremented accordingly.
Receiving in bundles can improve performance when more than one chunk of
data is available to receive,
by eliminating redundant round trips through the networking stack. Receive
bundles may be used by both single shot and multishot receive operations. Note
that, internally, bundles rely on the networking stack passing back how much
data is left in the socket after the initial receive. This means that the
initial receive may contain less buffers than what is available, with the
followup receive(s) containing more buffers. Available since 6.10.
.P

.SH RETURN VALUE
None
.SH ERRORS
The CQE
.I res
field will contain the result of the operation. On success, it contains
the number of bytes received. A return value of 0 indicates the peer
has performed an orderly shutdown. On error, it contains the negated
.I errno
value.
.PP
Common errors include:
.TP
.B -ECONNRESET
Connection reset by peer.
.TP
.B -ENOTCONN
The socket is not connected.
.TP
.B -EAGAIN
The socket is non-blocking and no data is available. Consider using
.B IORING_RECVSEND_POLL_FIRST
to handle this automatically.
.TP
.B -ENOBUFS
For multishot operations with provided buffers, no buffers are available
in the buffer group.
.SH NOTES
When using multishot receive with provided buffers, ensure that the buffer
ring has enough buffers to handle incoming data. If the buffer ring runs out,
the multishot operation will complete without
.B IORING_CQE_F_MORE
set in the CQE flags, and a new request must be submitted.
.PP
For high-throughput scenarios, consider using
.B IORING_RECVSEND_BUNDLE
to receive multiple buffers worth of data in a single operation, reducing
system call overhead.
.SH EXAMPLE
.SS Basic TCP receive
.EX
#include <stdio.h>
#include <liburing.h>

int receive_data(struct io_uring *ring, int sockfd,
                 void *buf, size_t len)
{
    struct io_uring_sqe *sqe;
    struct io_uring_cqe *cqe;
    int ret;

    sqe = io_uring_get_sqe(ring);
    io_uring_prep_recv(sqe, sockfd, buf, len, 0);

    ret = io_uring_submit(ring);
    if (ret < 0)
        return ret;

    ret = io_uring_wait_cqe(ring, &cqe);
    if (ret < 0)
        return ret;

    ret = cqe->res;
    io_uring_cqe_seen(ring, cqe);

    if (ret == 0) {
        printf("Connection closed by peer\\n");
    } else if (ret < 0) {
        fprintf(stderr, "recv failed: %d\\n", ret);
    } else {
        printf("Received %d bytes\\n", ret);
    }

    return ret;
}
.EE
.SS Multishot receive with provided buffers
.EX
#include <stdio.h>
#include <stdlib.h>
#include <liburing.h>

#define BGID        1
#define NUM_BUFFERS 16
#define BUF_SIZE    4096

struct io_uring_buf_ring *br;
char *buffer_base;

int setup_buffer_ring(struct io_uring *ring)
{
    int ret, i;

    /* Allocate buffer ring structure */
    ret = io_uring_buf_ring_mmap(ring, BGID, NUM_BUFFERS, &br);
    if (ret < 0)
        return ret;

    /* Allocate actual buffers */
    buffer_base = malloc(NUM_BUFFERS * BUF_SIZE);
    if (!buffer_base)
        return -ENOMEM;

    /* Add buffers to the ring */
    for (i = 0; i < NUM_BUFFERS; i++) {
        io_uring_buf_ring_add(br, buffer_base + i * BUF_SIZE,
                              BUF_SIZE, i,
                              io_uring_buf_ring_mask(NUM_BUFFERS), i);
    }
    io_uring_buf_ring_advance(br, NUM_BUFFERS);

    return 0;
}

void start_multishot_recv(struct io_uring *ring, int sockfd)
{
    struct io_uring_sqe *sqe;

    sqe = io_uring_get_sqe(ring);
    io_uring_prep_recv_multishot(sqe, sockfd, NULL, 0, 0);
    sqe->flags |= IOSQE_BUFFER_SELECT;
    sqe->buf_group = BGID;
    io_uring_sqe_set_data64(sqe, sockfd);

    io_uring_submit(ring);
}

void handle_recv_cqe(struct io_uring *ring, struct io_uring_cqe *cqe)
{
    int sockfd = io_uring_cqe_get_data64(cqe);

    if (cqe->res == 0) {
        printf("Connection closed\\n");
        return;
    }

    if (cqe->res > 0) {
        /* Get buffer ID from CQE flags */
        int bid = cqe->flags >> IORING_CQE_BUFFER_SHIFT;
        char *buf = buffer_base + bid * BUF_SIZE;

        printf("Received %d bytes in buffer %d\\n", cqe->res, bid);
        process_data(buf, cqe->res);

        /* Return buffer to the ring for reuse */
        io_uring_buf_ring_add(br, buf, BUF_SIZE, bid,
                              io_uring_buf_ring_mask(NUM_BUFFERS), 0);
        io_uring_buf_ring_advance(br, 1);
    }

    /* Check if multishot is still active */
    if (!(cqe->flags & IORING_CQE_F_MORE)) {
        printf("Multishot recv terminated, resubmitting\\n");
        start_multishot_recv(ring, sockfd);
    }
}
.EE
.SS Using POLL_FIRST with SOCK_NONEMPTY
.EX
#include <liburing.h>

/*
 * Efficient receive loop that avoids wasteful receive
 * attempts on empty sockets.
 */
void recv_loop(struct io_uring *ring, int sockfd, void *buf, size_t len)
{
    struct io_uring_sqe *sqe;
    struct io_uring_cqe *cqe;
    int poll_first = 1;  /* Start with polling */

    while (1) {
        sqe = io_uring_get_sqe(ring);
        io_uring_prep_recv(sqe, sockfd, buf, len, 0);

        if (poll_first)
            sqe->ioprio |= IORING_RECVSEND_POLL_FIRST;

        io_uring_submit(ring);
        io_uring_wait_cqe(ring, &cqe);

        if (cqe->res <= 0)
            break;

        process_data(buf, cqe->res);

        /*
         * If socket still has data, don't poll first next time.
         * Otherwise, poll first to avoid wasted recv attempts.
         */
        poll_first = !(cqe->flags & IORING_CQE_F_SOCK_NONEMPTY);

        io_uring_cqe_seen(ring, cqe);
    }

    io_uring_cqe_seen(ring, cqe);
}
.EE
.SH SEE ALSO
.BR io_uring_get_sqe (3),
.BR io_uring_submit (3),
.BR io_uring_buf_ring_init (3),
.BR io_uring_buf_ring_add (3),
.BR io_uring_buf_ring_mmap (3),
.BR io_uring_prep_send (3),
.BR recv (2)
